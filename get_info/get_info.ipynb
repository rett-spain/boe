{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "BASE_URL = \"https://boe.es/diario_boe/xml.php?id=BOE-S-{}\"\n",
    "BOE_URL = \"https://www.boe.es\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_boe_list(start_date):\n",
    "\n",
    "    current_date = datetime.strptime(start_date, \"%Y%m%d\")\n",
    "    valid_boe_list = []\n",
    "\n",
    "    while True:\n",
    "        formatted_date = current_date.strftime(\"%Y%m%d\")\n",
    "        url = BASE_URL.format(formatted_date)\n",
    "\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"lxml-xml\")  # Change to \"lxml\"\n",
    "\n",
    "            # Check if the file exists\n",
    "            error_element = soup.find(\"descripcion\")\n",
    "            if error_element and \"No se encontr√≥ el sumario original.\" in error_element.text:\n",
    "                print(f\"No data available for {formatted_date}.\")\n",
    "                break\n",
    "\n",
    "            # Valid date, append to the list\n",
    "            valid_boe_list.append(formatted_date)  # Append only the date\n",
    "\n",
    "            # Check the next date inside the XML, if it exists we continue\n",
    "            fecha_sig_element = soup.find(\"fechaSig\")\n",
    "            if fecha_sig_element and fecha_sig_element.text:\n",
    "                next_date_str = fecha_sig_element.text\n",
    "                next_date = datetime.strptime(next_date_str, \"%d/%m/%Y\")\n",
    "\n",
    "                current_date = next_date\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {formatted_date}. Status code: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "    return valid_boe_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_for_discapacidad(dates, label):\n",
    "    urls_for_discapacidad = {}\n",
    "\n",
    "    for date in dates:\n",
    "        url = BASE_URL.format(date)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"lxml-xml\")\n",
    "            items = soup.find_all(\"item\")\n",
    "\n",
    "            for item in items:\n",
    "                titulo_tag = item.find(\"titulo\")\n",
    "                if titulo_tag and label in titulo_tag.text.lower():\n",
    "                    url_pdf_tag = item.find(\"urlPdf\")\n",
    "                    url_xml_tag = item.find(\"urlXml\")\n",
    "                    if url_pdf_tag and url_xml_tag:\n",
    "                        urls_for_discapacidad[date] = {\n",
    "                            \"urlPdf\": url_pdf_tag.text,\n",
    "                            \"urlXml\": url_xml_tag.text\n",
    "                        }\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {date}. Status code: {response.status_code}\")\n",
    "\n",
    "    return urls_for_discapacidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(file_urls, folder=\"files\"):\n",
    "    # Create a folder for the files, one for PDFs and one for XMLs\n",
    "    os.makedirs(os.path.join(folder, \"pdf\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(folder, \"xml\"), exist_ok=True)\n",
    "\n",
    "    for date, urls in file_urls.items():\n",
    "        pdf_url = BOE_URL + urls['urlPdf']\n",
    "        xml_url = BOE_URL + urls['urlXml']\n",
    "\n",
    "        pdf_filename = os.path.join(folder, \"pdf\", f\"{date}.pdf\")\n",
    "        xml_filename = os.path.join(folder, \"xml\", f\"{date}.xml\")\n",
    "\n",
    "        download_file(pdf_url, pdf_filename)\n",
    "        download_file(xml_url, xml_filename)\n",
    "\n",
    "def download_file(url, filename):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded: {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {filename}. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20231101', '20231102', '20231103', '20231104', '20231106', '20231107', '20231108', '20231109', '20231110', '20231111', '20231113', '20231114', '20231115', '20231116', '20231117', '20231118', '20231120', '20231121', '20231122', '20231123', '20231124', '20231125']\n",
      "Date: 20231107, PDF URL for 'discapacidad': {'urlPdf': '/boe/dias/2023/11/07/pdfs/BOE-A-2023-22678.pdf', 'urlXml': '/diario_boe/xml.php?id=BOE-A-2023-22678'}\n",
      "Date: 20231108, PDF URL for 'discapacidad': {'urlPdf': '/boe/dias/2023/11/08/pdfs/BOE-B-2023-32820.pdf', 'urlXml': '/diario_boe/xml.php?id=BOE-B-2023-32820'}\n",
      "Date: 20231114, PDF URL for 'discapacidad': {'urlPdf': '/boe/dias/2023/11/14/pdfs/BOE-A-2023-23110.pdf', 'urlXml': '/diario_boe/xml.php?id=BOE-A-2023-23110'}\n",
      "Date: 20231115, PDF URL for 'discapacidad': {'urlPdf': '/boe/dias/2023/11/15/pdfs/BOE-B-2023-33684.pdf', 'urlXml': '/diario_boe/xml.php?id=BOE-B-2023-33684'}\n",
      "Date: 20231121, PDF URL for 'discapacidad': {'urlPdf': '/boe/dias/2023/11/21/pdfs/BOE-B-2023-34719.pdf', 'urlXml': '/diario_boe/xml.php?id=BOE-B-2023-34719'}\n",
      "Downloaded: downloaded_files\\pdf\\20231107.pdf\n",
      "Downloaded: downloaded_files\\xml\\20231107.xml\n",
      "Downloaded: downloaded_files\\pdf\\20231108.pdf\n",
      "Downloaded: downloaded_files\\xml\\20231108.xml\n",
      "Downloaded: downloaded_files\\pdf\\20231114.pdf\n",
      "Downloaded: downloaded_files\\xml\\20231114.xml\n",
      "Downloaded: downloaded_files\\pdf\\20231115.pdf\n",
      "Downloaded: downloaded_files\\xml\\20231115.xml\n",
      "Downloaded: downloaded_files\\pdf\\20231121.pdf\n",
      "Downloaded: downloaded_files\\xml\\20231121.xml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "start_date = \"20231101\"\n",
    "boe_list = get_valid_boe_list(start_date)\n",
    "print(boe_list)\n",
    "\n",
    "label = \"discapacidad\"\n",
    "pdf_urls_for_discapacidad = get_url_for_discapacidad(boe_list, label)\n",
    "\n",
    "for date, pdf_url in pdf_urls_for_discapacidad.items():\n",
    "    print(f\"Date: {date}, PDF URL for 'discapacidad': {pdf_url}\")\n",
    "\n",
    "download_files(pdf_urls_for_discapacidad, folder=\"downloaded_files\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
